[
    {
        "title": "Emotion Ratings: How Intensity, Annotation Confidence and Agreements are\n  Entangled",
        "summary": "  When humans judge the affective content of texts, they also implicitly assess\nthe correctness of such judgment, that is, their confidence. We hypothesize\nthat people's (in)confidence that they performed well in an annotation task\nleads to (dis)agreements among each other. If this is true, confidence may\nserve as a diagnostic tool for systematic differences in annotations. To probe\nour assumption, we conduct a study on a subset of the Corpus of Contemporary\nAmerican English, in which we ask raters to distinguish neutral sentences from\nemotion-bearing ones, while scoring the confidence of their answers. Confidence\nturns out to approximate inter-annotator disagreements. Further, we find that\nconfidence is correlated to emotion intensity: perceiving stronger affect in\ntext prompts annotators to more certain classification performances. This\ninsight is relevant for modelling studies of intensity, as it opens the\nquestion wether automatic regressors or classifiers actually predict intensity,\nor rather human's self-perceived confidence.\n"
    },
    {
        "title": "AraBERT and Farasa Segmentation Based Approach For Sarcasm and Sentiment\n  Detection in Arabic Tweets",
        "summary": "  This paper presents our strategy to tackle the EACL WANLP-2021 Shared Task 2:\nSarcasm and Sentiment Detection. One of the subtasks aims at developing a\nsystem that identifies whether a given Arabic tweet is sarcastic in nature or\nnot, while the other aims to identify the sentiment of the Arabic tweet. We\napproach the task in two steps. The first step involves pre processing the\nprovided ArSarcasm-v2 dataset by performing insertions, deletions and\nsegmentation operations on various parts of the text. The second step involves\nexperimenting with multiple variants of two transformer based models,\nAraELECTRA and AraBERT. Our final approach was ranked seventh and fourth in the\nSarcasm and Sentiment Detection subtasks respectively.\n"
    },
    {
        "title": "Conversational Norms for Human-Robot Dialogues",
        "summary": "  This paper describes a recently initiated research project aiming at\nsupporting development of computerised dialogue systems that handle breaches of\nconversational norms such as the Gricean maxims, which describe how dialogue\nparticipants ideally form their utterances in order to be informative,\nrelevant, brief, etc. Our approach is to model dialogue and norms with\nco-operating distributed grammar systems (CDGSs), and to develop methods to\ndetect breaches and to handle them in dialogue systems for verbal human-robot\ninteraction.\n"
    },
    {
        "title": "The Rediscovery Hypothesis: Language Models Need to Meet Linguistics",
        "summary": "  There is an ongoing debate in the NLP community whether modern language\nmodels contain linguistic knowledge, recovered through so-called probes. In\nthis paper, we study whether linguistic knowledge is a necessary condition for\nthe good performance of modern language models, which we call the\n\\textit{rediscovery hypothesis}. In the first place, we show that language\nmodels that are significantly compressed but perform well on their pretraining\nobjectives retain good scores when probed for linguistic structures. This\nresult supports the rediscovery hypothesis and leads to the second contribution\nof our paper: an information-theoretic framework that relates language modeling\nobjectives with linguistic information. This framework also provides a metric\nto measure the impact of linguistic information on the word prediction task. We\nreinforce our analytical results with various experiments, both on synthetic\nand on real NLP tasks in English.\n"
    },
    {
        "title": "MultiSubs: A Large-scale Multimodal and Multilingual Dataset",
        "summary": "  This paper introduces a large-scale multimodal and multilingual dataset that\naims to facilitate research on grounding words to images in their contextual\nusage in language. The dataset consists of images selected to unambiguously\nillustrate concepts expressed in sentences from movie subtitles. The dataset is\na valuable resource as (i) the images are aligned to text fragments rather than\nwhole sentences; (ii) multiple images are possible for a text fragment and a\nsentence; (iii) the sentences are free-form and real-world like; (iv) the\nparallel texts are multilingual. We set up a fill-in-the-blank game for humans\nto evaluate the quality of the automatic image selection process of our\ndataset. We show the utility of the dataset on two automatic tasks: (i)\nfill-in-the-blank; (ii) lexical translation. Results of the human evaluation\nand automatic models demonstrate that images can be a useful complement to the\ntextual context. The dataset will benefit research on visual grounding of words\nespecially in the context of free-form sentences, and can be obtained from\nhttps://doi.org/10.5281/zenodo.5034604 under a Creative Commons licence.\n"
    },
    {
        "title": "Random Feature Attention",
        "summary": "  Transformers are state-of-the-art models for a variety of sequence modeling\ntasks. At their core is an attention function which models pairwise\ninteractions between the inputs at every timestep. While attention is powerful,\nit does not scale efficiently to long sequences due to its quadratic time and\nspace complexity in the sequence length. We propose RFA, a linear time and\nspace attention that uses random feature methods to approximate the softmax\nfunction, and explore its application in transformers. RFA can be used as a\ndrop-in replacement for conventional softmax attention and offers a\nstraightforward way of learning with recency bias through an optional gating\nmechanism. Experiments on language modeling and machine translation demonstrate\nthat RFA achieves similar or better performance compared to strong transformer\nbaselines. In the machine translation experiment, RFA decodes twice as fast as\na vanilla transformer. Compared to existing efficient transformer variants, RFA\nis competitive in terms of both accuracy and efficiency on three long text\nclassification datasets. Our analysis shows that RFA's efficiency gains are\nespecially notable on long sequences, suggesting that RFA will be particularly\nuseful in tasks that require working with large inputs, fast decoding speed, or\nlow memory footprints.\n"
    },
    {
        "title": "Gradual Fine-Tuning for Low-Resource Domain Adaptation",
        "summary": "  Fine-tuning is known to improve NLP models by adapting an initial model\ntrained on more plentiful but less domain-salient examples to data in a target\ndomain. Such domain adaptation is typically done using one stage of\nfine-tuning. We demonstrate that gradually fine-tuning in a multi-stage process\ncan yield substantial further gains and can be applied without modifying the\nmodel or learning objective.\n"
    },
    {
        "title": "Zero-Shot Cross-Lingual Dependency Parsing through Contextual Embedding\n  Transformation",
        "summary": "  Linear embedding transformation has been shown to be effective for zero-shot\ncross-lingual transfer tasks and achieve surprisingly promising results.\nHowever, cross-lingual embedding space mapping is usually studied in static\nword-level embeddings, where a space transformation is derived by aligning\nrepresentations of translation pairs that are referred from dictionaries. We\nmove further from this line and investigate a contextual embedding alignment\napproach which is sense-level and dictionary-free. To enhance the quality of\nthe mapping, we also provide a deep view of properties of contextual\nembeddings, i.e., anisotropy problem and its solution. Experiments on zero-shot\ndependency parsing through the concept-shared space built by our embedding\ntransformation substantially outperform state-of-the-art methods using\nmultilingual embeddings.\n"
    },
    {
        "title": "Data Augmentation with Hierarchical SQL-to-Question Generation for\n  Cross-domain Text-to-SQL Parsing",
        "summary": "  Data augmentation has attracted a lot of research attention in the deep\nlearning era for its ability in alleviating data sparseness. The lack of\nlabeled data for unseen evaluation databases is exactly the major challenge for\ncross-domain text-to-SQL parsing. Previous works either require human\nintervention to guarantee the quality of generated data, or fail to handle\ncomplex SQL queries. This paper presents a simple yet effective data\naugmentation framework. First, given a database, we automatically produce a\nlarge number of SQL queries based on an abstract syntax tree grammar. For\nbetter distribution matching, we require that at least 80% of SQL patterns in\nthe training data are covered by generated queries. Second, we propose a\nhierarchical SQL-to-question generation model to obtain high-quality natural\nlanguage questions, which is the major contribution of this work. Finally, we\ndesign a simple sampling strategy that can greatly improve training efficiency\ngiven large amounts of generated data. Experiments on three cross-domain\ndatasets, i.e., WikiSQL and Spider in English, and DuSQL in Chinese, show that\nour proposed data augmentation framework can consistently improve performance\nover strong baselines, and the hierarchical generation component is the key for\nthe improvement.\n"
    },
    {
        "title": "Lex2vec: making Explainable Word Embeddings via Lexical Resources",
        "summary": "  In this technical report, we propose an algorithm, called Lex2vec that\nexploits lexical resources to inject information into word embeddings and name\nthe embedding dimensions by means of knowledge bases. We evaluate the optimal\nparameters to extract a number of informative labels that is readable and has a\ngood coverage for the embedding dimensions.\n"
    },
    {
        "title": "An Empirical Study of Compound PCFGs",
        "summary": "  Compound probabilistic context-free grammars (C-PCFGs) have recently\nestablished a new state of the art for unsupervised phrase-structure grammar\ninduction. However, due to the high space and time complexities of chart-based\nrepresentation and inference, it is difficult to investigate C-PCFGs\ncomprehensively. In this work, we rely on a fast implementation of C-PCFGs to\nconduct an evaluation complementary to that of~\\citet{kim-etal-2019-compound}.\nWe start by analyzing and ablating C-PCFGs on English treebanks. Our findings\nsuggest that (1) C-PCFGs are data-efficient and can generalize to unseen\nsentence/constituent lengths; and (2) C-PCFGs make the best use of\nsentence-level information in generating preterminal rule probabilities. We\nfurther conduct a multilingual evaluation of C-PCFGs. The experimental results\nshow that the best configurations of C-PCFGs, which are tuned on English, do\nnot always generalize to morphology-rich languages.\n"
    },
    {
        "title": "Few-shot Learning for Slot Tagging with Attentive Relational Network",
        "summary": "  Metric-based learning is a well-known family of methods for few-shot\nlearning, especially in computer vision. Recently, they have been used in many\nnatural language processing applications but not for slot tagging. In this\npaper, we explore metric-based learning methods in the slot tagging task and\npropose a novel metric-based learning architecture - Attentive Relational\nNetwork. Our proposed method extends relation networks, making them more\nsuitable for natural language processing applications in general, by leveraging\npretrained contextual embeddings such as ELMO and BERT and by using attention\nmechanism. The results on SNIPS data show that our proposed method outperforms\nother state-of-the-art metric-based learning methods.\n"
    },
    {
        "title": "OAG-BERT: Towards A Unified Backbone Language Model For Academic\n  Knowledge Services",
        "summary": "  Academic knowledge services have substantially facilitated the development of\nthe science enterprise by providing a plenitude of efficient research tools.\nHowever, many applications highly depend on ad-hoc models and expensive human\nlabeling to understand scientific contents, hindering deployments into real\nproducts. To build a unified backbone language model for different\nknowledge-intensive academic applications, we pre-train an academic language\nmodel OAG-BERT that integrates both the heterogeneous entity knowledge and\nscientific corpora in the Open Academic Graph (OAG) -- the largest public\nacademic graph to date. In OAG-BERT, we develop strategies for pre-training\ntext and entity data along with zero-shot inference techniques. In OAG-BERT, we\ndevelop strategies for pre-training text and entity data along with zero-shot\ninference techniques. Its zero-shot capability furthers the path to mitigate\nthe need of expensive annotations. OAG-BERT has been deployed for real-world\napplications, such as the reviewer recommendation function for National Nature\nScience Foundation of China (NSFC) -- one of the largest funding agencies in\nChina -- and paper tagging in AMiner. All codes and pre-trained models are\navailable via the CogDL toolkit.\n"
    },
    {
        "title": "NeurIPS 2020 NLC2CMD Competition: Translating Natural Language to Bash\n  Commands",
        "summary": "  The NLC2CMD Competition hosted at NeurIPS 2020 aimed to bring the power of\nnatural language processing to the command line. Participants were tasked with\nbuilding models that can transform descriptions of command line tasks in\nEnglish to their Bash syntax. This is a report on the competition with details\nof the task, metrics, data, attempted solutions, and lessons learned.\n"
    },
    {
        "title": "NaturalConv: A Chinese Dialogue Dataset Towards Multi-turn Topic-driven\n  Conversation",
        "summary": "  In this paper, we propose a Chinese multi-turn topic-driven conversation\ndataset, NaturalConv, which allows the participants to chat anything they want\nas long as any element from the topic is mentioned and the topic shift is\nsmooth. Our corpus contains 19.9K conversations from six domains, and 400K\nutterances with an average turn number of 20.1. These conversations contain\nin-depth discussions on related topics or widely natural transition between\nmultiple topics. We believe either way is normal for human conversation. To\nfacilitate the research on this corpus, we provide results of several benchmark\nmodels. Comparative results show that for this dataset, our current models are\nnot able to provide significant improvement by introducing background\nknowledge/topic. Therefore, the proposed dataset should be a good benchmark for\nfurther research to evaluate the validity and naturalness of multi-turn\nconversation systems. Our dataset is available at\nhttps://ai.tencent.com/ailab/nlp/dialogue/#datasets.\n"
    },
    {
        "title": "Detecting Extraneous Content in Podcasts",
        "summary": "  Podcast episodes often contain material extraneous to the main content, such\nas advertisements, interleaved within the audio and the written descriptions.\nWe present classifiers that leverage both textual and listening patterns in\norder to detect such content in podcast descriptions and audio transcripts. We\ndemonstrate that our models are effective by evaluating them on the downstream\ntask of podcast summarization and show that we can substantively improve ROUGE\nscores and reduce the extraneous content generated in the summaries.\n"
    },
    {
        "title": "A Survey on Spoken Language Understanding: Recent Advances and New\n  Frontiers",
        "summary": "  Spoken Language Understanding (SLU) aims to extract the semantics frame of\nuser queries, which is a core component in a task-oriented dialog system. With\nthe burst of deep neural networks and the evolution of pre-trained language\nmodels, the research of SLU has obtained significant breakthroughs. However,\nthere remains a lack of a comprehensive survey summarizing existing approaches\nand recent trends, which motivated the work presented in this article. In this\npaper, we survey recent advances and new frontiers in SLU. Specifically, we\ngive a thorough review of this research field, covering different aspects\nincluding (1) new taxonomy: we provide a new perspective for SLU filed,\nincluding single model vs. joint model, implicit joint modeling vs. explicit\njoint modeling in joint model, non pre-trained paradigm vs. pre-trained\nparadigm;(2) new frontiers: some emerging areas in complex SLU as well as the\ncorresponding challenges; (3) abundant open-source resources: to help the\ncommunity, we have collected, organized the related papers, baseline projects\nand leaderboard on a public website where SLU researchers could directly access\nto the recent progress. We hope that this survey can shed a light on future\nresearch in SLU field.\n"
    },
    {
        "title": "An Empirical Study of End-to-end Simultaneous Speech Translation\n  Decoding Strategies",
        "summary": "  This paper proposes a decoding strategy for end-to-end simultaneous speech\ntranslation. We leverage end-to-end models trained in offline mode and conduct\nan empirical study for two language pairs (English-to-German and\nEnglish-to-Portuguese). We also investigate different output token\ngranularities including characters and Byte Pair Encoding (BPE) units. The\nresults show that the proposed decoding approach allows to control BLEU/Average\nLagging trade-off along different latency regimes. Our best decoding settings\nachieve comparable results with a strong cascade model evaluated on the\nsimultaneous translation track of IWSLT 2020 shared task.\n"
    },
    {
        "title": "Enhanced Aspect-Based Sentiment Analysis Models with Progressive\n  Self-supervised Attention Learning",
        "summary": "  In aspect-based sentiment analysis (ABSA), many neural models are equipped\nwith an attention mechanism to quantify the contribution of each context word\nto sentiment prediction. However, such a mechanism suffers from one drawback:\nonly a few frequent words with sentiment polarities are tended to be taken into\nconsideration for final sentiment decision while abundant infrequent sentiment\nwords are ignored by models. To deal with this issue, we propose a progressive\nself-supervised attention learning approach for attentional ABSA models. In\nthis approach, we iteratively perform sentiment prediction on all training\ninstances, and continually learn useful attention supervision information in\nthe meantime. During training, at each iteration, context words with the\nhighest impact on sentiment prediction, identified based on their attention\nweights or gradients, are extracted as words with active/misleading influence\non the correct/incorrect prediction for each instance. Words extracted in this\nway are masked for subsequent iterations. To exploit these extracted words for\nrefining ABSA models, we augment the conventional training objective with a\nregularization term that encourages ABSA models to not only take full advantage\nof the extracted active context words but also decrease the weights of those\nmisleading words. We integrate the proposed approach into three\nstate-of-the-art neural ABSA models. Experiment results and in-depth analyses\nshow that our approach yields better attention results and significantly\nenhances the performance of all three models. We release the source code and\ntrained models at https://github.com/DeepLearnXMU/PSSAttention.\n"
    },
    {
        "title": "Syntactic and Semantic-driven Learning for Open Information Extraction",
        "summary": "  One of the biggest bottlenecks in building accurate, high coverage neural\nopen IE systems is the need for large labelled corpora. The diversity of open\ndomain corpora and the variety of natural language expressions further\nexacerbate this problem. In this paper, we propose a syntactic and\nsemantic-driven learning approach, which can learn neural open IE models\nwithout any human-labelled data by leveraging syntactic and semantic knowledge\nas noisier, higher-level supervisions. Specifically, we first employ syntactic\npatterns as data labelling functions and pretrain a base model using the\ngenerated labels. Then we propose a syntactic and semantic-driven reinforcement\nlearning algorithm, which can effectively generalize the base model to open\nsituations with high accuracy. Experimental results show that our approach\nsignificantly outperforms the supervised counterparts, and can even achieve\ncompetitive performance to supervised state-of-the-art (SoA) model\n"
    },
    {
        "title": "Dual Pointer Network for Fast Extraction of Multiple Relations in a\n  Sentence",
        "summary": "  Relation extraction is a type of information extraction task that recognizes\nsemantic relationships between entities in a sentence. Many previous studies\nhave focused on extracting only one semantic relation between two entities in a\nsingle sentence. However, multiple entities in a sentence are associated\nthrough various relations. To address this issue, we propose a relation\nextraction model based on a dual pointer network with a multi-head attention\nmechanism. The proposed model finds n-to-1 subject-object relations using a\nforward object decoder. Then, it finds 1-to-n subject-object relations using a\nbackward subject decoder. Our experiments confirmed that the proposed model\noutperformed previous models, with an F1-score of 80.8% for the ACE-2005 corpus\nand an F1-score of 78.3% for the NYT corpus.\n"
    },
    {
        "title": "Graph-Based Tri-Attention Network for Answer Ranking in CQA",
        "summary": "  In community-based question answering (CQA) platforms, automatic answer\nranking for a given question is critical for finding potentially popular\nanswers in early times. The mainstream approaches learn to generate answer\nranking scores based on the matching degree between question and answer\nrepresentations as well as the influence of respondents. However, they\nencounter two main limitations: (1) Correlations between answers in the same\nquestion are often overlooked. (2) Question and respondent representations are\nbuilt independently of specific answers before affecting answer\nrepresentations. To address the limitations, we devise a novel graph-based\ntri-attention network, namely GTAN, which has two innovations. First, GTAN\nproposes to construct a graph for each question and learn answer correlations\nfrom each graph through graph neural networks (GNNs). Second, based on the\nrepresentations learned from GNNs, an alternating tri-attention method is\ndeveloped to alternatively build target-aware respondent representations,\nanswer-specific question representations, and context-aware answer\nrepresentations by attention computation. GTAN finally integrates the above\nrepresentations to generate answer ranking scores. Experiments on three\nreal-world CQA datasets demonstrate GTAN significantly outperforms\nstate-of-the-art answer ranking methods, validating the rationality of the\nnetwork architecture.\n"
    },
    {
        "title": "Fine-tuning Pretrained Multilingual BERT Model for Indonesian\n  Aspect-based Sentiment Analysis",
        "summary": "  Although previous research on Aspect-based Sentiment Analysis (ABSA) for\nIndonesian reviews in hotel domain has been conducted using CNN and XGBoost,\nits model did not generalize well in test data and high number of OOV words\ncontributed to misclassification cases. Nowadays, most state-of-the-art results\nfor wide array of NLP tasks are achieved by utilizing pretrained language\nrepresentation. In this paper, we intend to incorporate one of the foremost\nlanguage representation model, BERT, to perform ABSA in Indonesian reviews\ndataset. By combining multilingual BERT (m-BERT) with task transformation\nmethod, we manage to achieve significant improvement by 8% on the F1-score\ncompared to the result from our previous study.\n"
    },
    {
        "title": "Multi-document Summarization using Semantic Role Labeling and Semantic\n  Graph for Indonesian News Article",
        "summary": "  In this paper, we proposed a multi-document summarization system using\nsemantic role labeling (SRL) and semantic graph for Indonesian news articles.\nIn order to improve existing summarizer, our system modified summarizer that\nemployed subject, predicate, object, and adverbial (SVOA) extraction for\npredicate argument structure (PAS) extraction. SVOA extraction is replaced with\nSRL model for Indonesian. We also replace the genetic algorithm to identify\nimportant PAS with the decision tree classifier since the summarizer without\ngenetic algorithm gave better performance. The decision tree model is employed\nto identify important PAS. The decision tree model with 10 features achieved\nbetter performance than decision tree with 4 sentence features. Experiments and\nevaluations are conducted to generate 100 words summary and 200 words summary.\nThe evaluation shows the proposed model get 0.313 average ROUGE-2 recall in 100\nwords summary and 0.394 average ROUGE-2 recall in 200 words summary.\n"
    },
    {
        "title": "Leveraging Recursive Processing for Neural-Symbolic Affect-Target\n  Associations",
        "summary": "  Explaining the outcome of deep learning decisions based on affect is\nchallenging but necessary if we expect social companion robots to interact with\nusers on an emotional level. In this paper, we present a commonsense approach\nthat utilizes an interpretable hybrid neural-symbolic system to associate\nextracted targets, noun chunks determined to be associated with the expressed\nemotion, with affective labels from a natural language expression. We leverage\na pre-trained neural network that is well adapted to tree and sub-tree\nprocessing, the Dependency Tree-LSTM, to learn the affect labels of dynamic\ntargets, determined through symbolic rules, in natural language. We find that\nmaking use of the unique properties of the recursive network provides higher\naccuracy and interpretability when compared to other unstructured and\nsequential methods for determining target-affect associations in an\naspect-based sentiment analysis task.\n"
    },
    {
        "title": "There Once Was a Really Bad Poet, It Was Automated but You Didn't Know\n  It",
        "summary": "  Limerick generation exemplifies some of the most difficult challenges faced\nin poetry generation, as the poems must tell a story in only five lines, with\nconstraints on rhyme, stress, and meter. To address these challenges, we\nintroduce LimGen, a novel and fully automated system for limerick generation\nthat outperforms state-of-the-art neural network-based poetry models, as well\nas prior rule-based poetry models. LimGen consists of three important pieces:\nthe Adaptive Multi-Templated Constraint algorithm that constrains our search to\nthe space of realistic poems, the Multi-Templated Beam Search algorithm which\nsearches efficiently through the space, and the probabilistic Storyline\nalgorithm that provides coherent storylines related to a user-provided prompt\nword. The resulting limericks satisfy poetic constraints and have thematically\ncoherent storylines, which are sometimes even funny (when we are lucky).\n"
    },
    {
        "title": "AnswerQuest: A System for Generating Question-Answer Items from\n  Multi-Paragraph Documents",
        "summary": "  One strategy for facilitating reading comprehension is to present information\nin a question-and-answer format. We demo a system that integrates the tasks of\nquestion answering (QA) and question generation (QG) in order to produce Q&A\nitems that convey the content of multi-paragraph documents. We report some\nexperiments for QA and QG that yield improvements on both tasks, and assess how\nthey interact to produce a list of Q&A items for a text. The demo is accessible\nat qna.sdl.com.\n"
    },
    {
        "title": "Overcoming Poor Word Embeddings with Word Definitions",
        "summary": "  Modern natural language understanding models depend on pretrained subword\nembeddings, but applications may need to reason about words that were never or\nrarely seen during pretraining. We show that examples that depend critically on\na rarer word are more challenging for natural language inference models. Then\nwe explore how a model could learn to use definitions, provided in natural\ntext, to overcome this handicap. Our model's understanding of a definition is\nusually weaker than a well-modeled word embedding, but it recovers most of the\nperformance gap from using a completely untrained word.\n"
    },
    {
        "title": "Neural networks can understand compositional functions that humans do\n  not, in the context of emergent communication",
        "summary": "  We show that it is possible to craft transformations that, applied to\ncompositional grammars, result in grammars that neural networks can learn\neasily, but humans do not. This could explain the disconnect between current\nmetrics of compositionality, that are arguably human-centric, and the ability\nof neural networks to generalize to unseen examples. We propose to use the\ntransformations as a benchmark, ICY, which could be used to measure aspects of\nthe compositional inductive bias of networks, and to search for networks with\nsimilar compositional inductive biases to humans. As an example of this\napproach, we propose a hierarchical model, HU-RNN, which shows an inductive\nbias towards position-independent, word-like groups of tokens.\n"
    },
    {
        "title": "MTLHealth: A Deep Learning System for Detecting Disturbing Content in\n  Student Essays",
        "summary": "  Essay submissions to standardized tests like the ACT occasionally include\nreferences to bullying, self-harm, violence, and other forms of disturbing\ncontent. Graders must take great care to identify cases like these and decide\nwhether to alert authorities on behalf of students who may be in danger. There\nis a growing need for robust computer systems to support human decision-makers\nby automatically flagging potential instances of disturbing content. This paper\ndescribes MTLHealth, a disturbing content detection pipeline built around\nrecent advances from computational linguistics, particularly pre-trained\nlanguage model Transformer networks.\n"
    },
    {
        "title": "Syntax-BERT: Improving Pre-trained Transformers with Syntax Trees",
        "summary": "  Pre-trained language models like BERT achieve superior performances in\nvarious NLP tasks without explicit consideration of syntactic information.\nMeanwhile, syntactic information has been proved to be crucial for the success\nof NLP applications. However, how to incorporate the syntax trees effectively\nand efficiently into pre-trained Transformers is still unsettled. In this\npaper, we address this problem by proposing a novel framework named\nSyntax-BERT. This framework works in a plug-and-play mode and is applicable to\nan arbitrary pre-trained checkpoint based on Transformer architecture.\nExperiments on various datasets of natural language understanding verify the\neffectiveness of syntax trees and achieve consistent improvement over multiple\npre-trained models, including BERT, RoBERTa, and T5.\n"
    },
    {
        "title": "Empathetic BERT2BERT Conversational Model: Learning Arabic Language\n  Generation with Little Data",
        "summary": "  Enabling empathetic behavior in Arabic dialogue agents is an important aspect\nof building human-like conversational models. While Arabic Natural Language\nProcessing has seen significant advances in Natural Language Understanding\n(NLU) with language models such as AraBERT, Natural Language Generation (NLG)\nremains a challenge. The shortcomings of NLG encoder-decoder models are\nprimarily due to the lack of Arabic datasets suitable to train NLG models such\nas conversational agents. To overcome this issue, we propose a\ntransformer-based encoder-decoder initialized with AraBERT parameters. By\ninitializing the weights of the encoder and decoder with AraBERT pre-trained\nweights, our model was able to leverage knowledge transfer and boost\nperformance in response generation. To enable empathy in our conversational\nmodel, we train it using the ArabicEmpatheticDialogues dataset and achieve high\nperformance in empathetic response generation. Specifically, our model achieved\na low perplexity value of 17.0 and an increase in 5 BLEU points compared to the\nprevious state-of-the-art model. Also, our proposed model was rated highly by\n85 human evaluators, validating its high capability in exhibiting empathy while\ngenerating relevant and fluent responses in open-domain settings.\n"
    },
    {
        "title": "Automatic Difficulty Classification of Arabic Sentences",
        "summary": "  In this paper, we present a Modern Standard Arabic (MSA) Sentence difficulty\nclassifier, which predicts the difficulty of sentences for language learners\nusing either the CEFR proficiency levels or the binary classification as simple\nor complex. We compare the use of sentence embeddings of different kinds\n(fastText, mBERT , XLM-R and Arabic-BERT), as well as traditional language\nfeatures such as POS tags, dependency trees, readability scores and frequency\nlists for language learners. Our best results have been achieved using\nfined-tuned Arabic-BERT. The accuracy of our 3-way CEFR classification is F-1\nof 0.80 and 0.75 for Arabic-Bert and XLM-R classification respectively and 0.71\nSpearman correlation for regression. Our binary difficulty classifier reaches\nF-1 0.94 and F-1 0.98 for sentence-pair semantic similarity classifier.\n"
    },
    {
        "title": "Improving Text-to-SQL with Schema Dependency Learning",
        "summary": "  Text-to-SQL aims to map natural language questions to SQL queries. The\nsketch-based method combined with execution-guided (EG) decoding strategy has\nshown a strong performance on the WikiSQL benchmark. However, execution-guided\ndecoding relies on database execution, which significantly slows down the\ninference process and is hence unsatisfactory for many real-world applications.\nIn this paper, we present the Schema Dependency guided multi-task Text-to-SQL\nmodel (SDSQL) to guide the network to effectively capture the interactions\nbetween questions and schemas. The proposed model outperforms all existing\nmethods in both the settings with or without EG. We show the schema dependency\nlearning partially cover the benefit from EG and alleviates the need for it.\nSDSQL without EG significantly reduces time consumption during inference,\nsacrificing only a small amount of performance and provides more flexibility\nfor downstream applications.\n"
    },
    {
        "title": "\"Sharks are not the threat humans are\": Argument Component Segmentation\n  in School Student Essays",
        "summary": "  Argument mining is often addressed by a pipeline method where segmentation of\ntext into argumentative units is conducted first and proceeded by an argument\ncomponent identification task. In this research, we apply a token-level\nclassification to identify claim and premise tokens from a new corpus of\nargumentative essays written by middle school students. To this end, we compare\na variety of state-of-the-art models such as discrete features and deep\nlearning architectures (e.g., BiLSTM networks and BERT-based architectures) to\nidentify the argument components. We demonstrate that a BERT-based multi-task\nlearning architecture (i.e., token and sentence level classification)\nadaptively pretrained on a relevant unlabeled dataset obtains the best results\n"
    },
    {
        "title": "MCR-Net: A Multi-Step Co-Interactive Relation Network for Unanswerable\n  Questions on Machine Reading Comprehension",
        "summary": "  Question answering systems usually use keyword searches to retrieve potential\npassages related to a question, and then extract the answer from passages with\nthe machine reading comprehension methods. However, many questions tend to be\nunanswerable in the real world. In this case, it is significant and challenging\nhow the model determines when no answer is supported by the passage and\nabstains from answering. Most of the existing systems design a simple\nclassifier to determine answerability implicitly without explicitly modeling\nmutual interaction and relation between the question and passage, leading to\nthe poor performance for determining the unanswerable questions. To tackle this\nproblem, we propose a Multi-Step Co-Interactive Relation Network (MCR-Net) to\nexplicitly model the mutual interaction and locate key clues from coarse to\nfine by introducing a co-interactive relation module. The co-interactive\nrelation module contains a stack of interaction and fusion blocks to\ncontinuously integrate and fuse history-guided and current-query-guided clues\nin an explicit way. Experiments on the SQuAD 2.0 and DuReader datasets show\nthat our model achieves a remarkable improvement, outperforming the BERT-style\nbaselines in literature. Visualization analysis also verifies the importance of\nthe mutual interaction between the question and passage.\n"
    },
    {
        "title": "InFillmore: Frame-Guided Language Generation with Bidirectional Context",
        "summary": "  We propose a structured extension to bidirectional-context conditional\nlanguage generation, or \"infilling,\" inspired by Frame Semantic theory\n(Fillmore, 1976). Guidance is provided through two approaches: (1) model\nfine-tuning, conditioning directly on observed symbolic frames, and (2) a novel\nextension to disjunctive lexically constrained decoding that leverages frame\nsemantic lexical units. Automatic and human evaluations confirm that\nframe-guided generation allows for explicit manipulation of intended infill\nsemantics, with minimal loss in distinguishability from human-generated text.\nOur methods flexibly apply to a variety of use scenarios, and we provide a\ncodebase and interactive demo available from\nhttps://nlp.jhu.edu/demos/infillmore.\n"
    },
    {
        "title": "Fast and Effective Biomedical Entity Linking Using a Dual Encoder",
        "summary": "  Biomedical entity linking is the task of identifying mentions of biomedical\nconcepts in text documents and mapping them to canonical entities in a target\nthesaurus. Recent advancements in entity linking using BERT-based models follow\na retrieve and rerank paradigm, where the candidate entities are first selected\nusing a retriever model, and then the retrieved candidates are ranked by a\nreranker model. While this paradigm produces state-of-the-art results, they are\nslow both at training and test time as they can process only one mention at a\ntime. To mitigate these issues, we propose a BERT-based dual encoder model that\nresolves multiple mentions in a document in one shot. We show that our proposed\nmodel is multiple times faster than existing BERT-based models while being\ncompetitive in accuracy for biomedical entity linking. Additionally, we modify\nour dual encoder model for end-to-end biomedical entity linking that performs\nboth mention span detection and entity disambiguation and out-performs two\nrecently proposed models.\n"
    },
    {
        "title": "Domain Controlled Title Generation with Human Evaluation",
        "summary": "  We study automatic title generation and present a method for generating\ndomain-controlled titles for scientific articles. A good title allows you to\nget the attention that your research deserves. A title can be interpreted as a\nhigh-compression description of a document containing information on the\nimplemented process. For domain-controlled titles, we used the pre-trained\ntext-to-text transformer model and the additional token technique. Title tokens\nare sampled from a local distribution (which is a subset of global vocabulary)\nof the domain-specific vocabulary and not global vocabulary, thereby generating\na catchy title and closely linking it to its corresponding abstract. Generated\ntitles looked realistic, convincing, and very close to the ground truth. We\nhave performed automated evaluation using ROUGE metric and human evaluation\nusing five parameters to make a comparison between human and machine-generated\ntitles. The titles produced were considered acceptable with higher metric\nratings in contrast to the original titles. Thus we concluded that our research\nproposes a promising method for domain-controlled title generation.\n"
    },
    {
        "title": "Few-Shot Learning of an Interleaved Text Summarization Model by\n  Pretraining with Synthetic Data",
        "summary": "  Interleaved texts, where posts belonging to different threads occur in a\nsequence, commonly occur in online chat posts, so that it can be time-consuming\nto quickly obtain an overview of the discussions. Existing systems first\ndisentangle the posts by threads and then extract summaries from those threads.\nA major issue with such systems is error propagation from the disentanglement\ncomponent. While end-to-end trainable summarization system could obviate\nexplicit disentanglement, such systems require a large amount of labeled data.\nTo address this, we propose to pretrain an end-to-end trainable hierarchical\nencoder-decoder system using synthetic interleaved texts. We show that by\nfine-tuning on a real-world meeting dataset (AMI), such a system out-performs a\ntraditional two-step system by 22%. We also compare against transformer models\nand observed that pretraining with synthetic data both the encoder and decoder\noutperforms the BertSumExtAbs transformer model which pretrains only the\nencoder on a large dataset.\n"
    },
    {
        "title": "A Topological Approach to Compare Document Semantics Based on a New\n  Variant of Syntactic N-grams",
        "summary": "  This paper delivers a new perspective of thinking and utilizing syntactic\nn-grams (sn-grams). Sn-grams are a type of non-linear n-grams which have been\nplaying a critical role in many NLP tasks. Introducing sn-grams to comparing\ndocument semantics thus is an appealing application, and few studies have\nreported progress at this. However, when proceeding on this application, we\nfound three major issues of sn-grams: lack of significance, being sensitive to\nword orders and failing on capture indirect syntactic relations. To address\nthese issues, we propose a new variant of sn-grams named generalized phrases\n(GPs). Then based on GPs we propose a topological approach, named DSCoH, to\ncompute document semantic similarities. DSCoH has been extensively tested on\nthe document semantics comparison and the document clustering tasks. The\nexperimental results show that DSCoH can outperform state-of-the-art\nembedding-based methods.\n"
    },
    {
        "title": "Contrastive Semi-supervised Learning for ASR",
        "summary": "  Pseudo-labeling is the most adopted method for pre-training automatic speech\nrecognition (ASR) models. However, its performance suffers from the supervised\nteacher model's degrading quality in low-resource setups and under domain\ntransfer. Inspired by the successes of contrastive representation learning for\ncomputer vision and speech applications, and more recently for supervised\nlearning of visual objects, we propose Contrastive Semi-supervised Learning\n(CSL). CSL eschews directly predicting teacher-generated pseudo-labels in favor\nof utilizing them to select positive and negative examples. In the challenging\ntask of transcribing public social media videos, using CSL reduces the WER by\n8% compared to the standard Cross-Entropy pseudo-labeling (CE-PL) when 10hr of\nsupervised data is used to annotate 75,000hr of videos. The WER reduction jumps\nto 19% under the ultra low-resource condition of using 1hr labels for teacher\nsupervision. CSL generalizes much better in out-of-domain conditions, showing\nup to 17% WER reduction compared to the best CE-PL pre-trained model.\n"
    },
    {
        "title": "Improving Document-Level Sentiment Classification Using Importance of\n  Sentences",
        "summary": "  Previous researchers have considered sentiment analysis as a document\nclassification task, in which input documents are classified into predefined\nsentiment classes. Although there are sentences in a document that support\nimportant evidences for sentiment analysis and sentences that do not, they have\ntreated the document as a bag of sentences. In other words, they have not\nconsidered the importance of each sentence in the document. To effectively\ndetermine polarity of a document, each sentence in the document should be dealt\nwith different degrees of importance. To address this problem, we propose a\ndocument-level sentence classification model based on deep neural networks, in\nwhich the importance degrees of sentences in documents are automatically\ndetermined through gate mechanisms. To verify our new sentiment analysis model,\nwe conducted experiments using the sentiment datasets in the four different\ndomains such as movie reviews, hotel reviews, restaurant reviews, and music\nreviews. In the experiments, the proposed model outperformed previous\nstate-of-the-art models that do not consider importance differences of\nsentences in a document. The experimental results show that the importance of\nsentences should be considered in a document-level sentiment classification\ntask.\n"
    },
    {
        "title": "Detecting Inappropriate Messages on Sensitive Topics that Could Harm a\n  Company's Reputation",
        "summary": "  Not all topics are equally \"flammable\" in terms of toxicity: a calm\ndiscussion of turtles or fishing less often fuels inappropriate toxic dialogues\nthan a discussion of politics or sexual minorities. We define a set of\nsensitive topics that can yield inappropriate and toxic messages and describe\nthe methodology of collecting and labeling a dataset for appropriateness. While\ntoxicity in user-generated data is well-studied, we aim at defining a more\nfine-grained notion of inappropriateness. The core of inappropriateness is that\nit can harm the reputation of a speaker. This is different from toxicity in two\nrespects: (i) inappropriateness is topic-related, and (ii) inappropriate\nmessage is not toxic but still unacceptable. We collect and release two\ndatasets for Russian: a topic-labeled dataset and an appropriateness-labeled\ndataset. We also release pre-trained classification models trained on this\ndata.\n"
    },
    {
        "title": "Tell Me Why You Feel That Way: Processing Compositional Dependency for\n  Tree-LSTM Aspect Sentiment Triplet Extraction (TASTE)",
        "summary": "  Sentiment analysis has transitioned from classifying the sentiment of an\nentire sentence to providing the contextual information of what targets exist\nin a sentence, what sentiment the individual targets have, and what the causal\nwords responsible for that sentiment are. However, this has led to elaborate\nrequirements being placed on the datasets needed to train neural networks on\nthe joint triplet task of determining an entity, its sentiment, and the causal\nwords for that sentiment. Requiring this kind of data for training systems is\nproblematic, as they suffer from stacking subjective annotations and domain\nover-fitting leading to poor model generalisation when applied in new contexts.\nThese problems are also likely to be compounded as we attempt to jointly\ndetermine additional contextual elements in the future. To mitigate these\nproblems, we present a hybrid neural-symbolic method utilising a Dependency\nTree-LSTM's compositional sentiment parse structure and complementary symbolic\nrules to correctly extract target-sentiment-cause triplets from sentences\nwithout the need for triplet training data. We show that this method has the\npotential to perform in line with state-of-the-art approaches while also\nsimplifying the data required and providing a degree of interpretability\nthrough the Tree-LSTM.\n"
    },
    {
        "title": "How does Truth Evolve into Fake News? An Empirical Study of Fake News\n  Evolution",
        "summary": "  Automatically identifying fake news from the Internet is a challenging\nproblem in deception detection tasks. Online news is modified constantly during\nits propagation, e.g., malicious users distort the original truth and make up\nfake news. However, the continuous evolution process would generate\nunprecedented fake news and cheat the original model. We present the Fake News\nEvolution (FNE) dataset: a new dataset tracking the fake news evolution\nprocess. Our dataset is composed of 950 paired data, each of which consists of\narticles representing the three significant phases of the evolution process,\nwhich are the truth, the fake news, and the evolved fake news. We observe the\nfeatures during the evolution and they are the disinformation techniques, text\nsimilarity, top 10 keywords, classification accuracy, parts of speech, and\nsentiment properties.\n"
    },
    {
        "title": "Self-Learning for Zero Shot Neural Machine Translation",
        "summary": "  Neural Machine Translation (NMT) approaches employing monolingual data are\nshowing steady improvements in resource rich conditions. However, evaluations\nusing real-world low-resource languages still result in unsatisfactory\nperformance. This work proposes a novel zero-shot NMT modeling approach that\nlearns without the now-standard assumption of a pivot language sharing parallel\ndata with the zero-shot source and target languages. Our approach is based on\nthree stages: initialization from any pre-trained NMT model observing at least\nthe target language, augmentation of source sides leveraging target monolingual\ndata, and learning to optimize the initial model to the zero-shot pair, where\nthe latter two constitute a self-learning cycle. Empirical findings involving\nfour diverse (in terms of a language family, script and relatedness) zero-shot\npairs show the effectiveness of our approach with up to +5.93 BLEU improvement\nagainst a supervised bilingual baseline. Compared to unsupervised NMT,\nconsistent improvements are observed even in a domain-mismatch setting,\nattesting to the usability of our method.\n"
    },
    {
        "title": "A Result based Portable Framework for Spoken Language Understanding",
        "summary": "  Spoken language understanding (SLU), which is a core component of the\ntask-oriented dialogue system, has made substantial progress in the research of\nsingle-turn dialogue. However, the performance in multi-turn dialogue is still\nnot satisfactory in the sense that the existing multi-turn SLU methods have low\nportability and compatibility for other single-turn SLU models. Further,\nexisting multi-turn SLU methods do not exploit the historical predicted results\nwhen predicting the current utterance, which wastes helpful information. To gap\nthose shortcomings, in this paper, we propose a novel Result-based Portable\nFramework for SLU (RPFSLU). RPFSLU allows most existing single-turn SLU models\nto obtain the contextual information from multi-turn dialogues and takes full\nadvantage of predicted results in the dialogue history during the current\nprediction. Experimental results on the public dataset KVRET have shown that\nall SLU models in baselines acquire enhancement by RPFSLU on multi-turn SLU\ntasks.\n"
    },
    {
        "title": "Team Phoenix at WASSA 2021: Emotion Analysis on News Stories with\n  Pre-Trained Language Models",
        "summary": "  Emotion is fundamental to humanity. The ability to perceive, understand and\nrespond to social interactions in a human-like manner is one of the most\ndesired capabilities in artificial agents, particularly in social-media bots.\nOver the past few years, computational understanding and detection of emotional\naspects in language have been vital in advancing human-computer interaction.\nThe WASSA Shared Task 2021 released a dataset of news-stories across two\ntracks, Track-1 for Empathy and Distress Prediction and Track-2 for\nMulti-Dimension Emotion prediction at the essay-level. We describe our system\nentry for the WASSA 2021 Shared Task (for both Track-1 and Track-2), where we\nleveraged the information from Pre-trained language models for Track-specific\nTasks. Our proposed models achieved an Average Pearson Score of 0.417 and a\nMacro-F1 Score of 0.502 in Track 1 and Track 2, respectively. In the Shared\nTask leaderboard, we secured 4th rank in Track 1 and 2nd rank in Track 2.\n"
    },
    {
        "title": "Knowledge-based Extraction of Cause-Effect Relations from Biomedical\n  Text",
        "summary": "  We propose a knowledge-based approach for extraction of Cause-Effect (CE)\nrelations from biomedical text. Our approach is a combination of an\nunsupervised machine learning technique to discover causal triggers and a set\nof high-precision linguistic rules to identify cause/effect arguments of these\ncausal triggers. We evaluate our approach using a corpus of 58,761\nLeukaemia-related PubMed abstracts consisting of 568,528 sentences. We could\nextract 152,655 CE triplets from this corpus where each triplet consists of a\ncause phrase, an effect phrase and a causal trigger. As compared to the\nexisting knowledge base - SemMedDB (Kilicoglu et al., 2012), the number of\nextractions are almost twice. Moreover, the proposed approach outperformed the\nexisting technique SemRep (Rindflesch and Fiszman, 2003) on a dataset of 500\nsentences.\n"
    },
    {
        "title": "Techniques for Jointly Extracting Entities and Relations: A Survey",
        "summary": "  Relation Extraction is an important task in Information Extraction which\ndeals with identifying semantic relations between entity mentions.\nTraditionally, relation extraction is carried out after entity extraction in a\n\"pipeline\" fashion, so that relation extraction only focuses on determining\nwhether any semantic relation exists between a pair of extracted entity\nmentions. This leads to propagation of errors from entity extraction stage to\nrelation extraction stage. Also, entity extraction is carried out without any\nknowledge about the relations. Hence, it was observed that jointly performing\nentity and relation extraction is beneficial for both the tasks. In this paper,\nwe survey various techniques for jointly extracting entities and relations. We\ncategorize techniques based on the approach they adopt for joint extraction,\ni.e. whether they employ joint inference or joint modelling or both. We further\ndescribe some representative techniques for joint inference and joint\nmodelling. We also describe two standard datasets, evaluation techniques and\nperformance of the joint extraction approaches on these datasets. We present a\nbrief analysis of application of a general domain joint extraction approach to\na Biomedical dataset. This survey is useful for researchers as well as\npractitioners in the field of Information Extraction, by covering a broad\nlandscape of joint extraction techniques.\n"
    },
    {
        "title": "Identifying ARDS using the Hierarchical Attention Network with Sentence\n  Objectives Framework",
        "summary": "  Acute respiratory distress syndrome (ARDS) is a life-threatening condition\nthat is often undiagnosed or diagnosed late. ARDS is especially prominent in\nthose infected with COVID-19. We explore the automatic identification of ARDS\nindicators and confounding factors in free-text chest radiograph reports. We\npresent a new annotated corpus of chest radiograph reports and introduce the\nHierarchical Attention Network with Sentence Objectives (HANSO) text\nclassification framework. HANSO utilizes fine-grained annotations to improve\ndocument classification performance. HANSO can extract ARDS-related information\nwith high performance by leveraging relation annotations, even if the annotated\nspans are noisy. Using annotated chest radiograph images as a gold standard,\nHANSO identifies bilateral infiltrates, an indicator of ARDS, in chest\nradiograph reports with performance (0.87 F1) comparable to human annotations\n(0.84 F1). This algorithm could facilitate more efficient and expeditious\nidentification of ARDS by clinicians and researchers and contribute to the\ndevelopment of new therapies to improve patient care.\n"
    },
    {
        "title": "ReportAGE: Automatically extracting the exact age of Twitter users based\n  on self-reports in tweets",
        "summary": "  Advancing the utility of social media data for research applications requires\nmethods for automatically detecting demographic information about social media\nstudy populations, including users' age. The objective of this study was to\ndevelop and evaluate a method that automatically identifies the exact age of\nusers based on self-reports in their tweets. Our end-to-end automatic natural\nlanguage processing (NLP) pipeline, ReportAGE, includes query patterns to\nretrieve tweets that potentially mention an age, a classifier to distinguish\nretrieved tweets that self-report the user's exact age (\"age\" tweets) and those\nthat do not (\"no age\" tweets), and rule-based extraction to identify the age.\nTo develop and evaluate ReportAGE, we manually annotated 11,000 tweets that\nmatched the query patterns. Based on 1000 tweets that were annotated by all\nfive annotators, inter-annotator agreement (Fleiss' kappa) was 0.80 for\ndistinguishing \"age\" and \"no age\" tweets, and 0.95 for identifying the exact\nage among the \"age\" tweets on which the annotators agreed. A deep neural\nnetwork classifier, based on a RoBERTa-Large pretrained model, achieved the\nhighest F1-score of 0.914 (precision = 0.905, recall = 0.942) for the \"age\"\nclass. When the age extraction was evaluated using the classifier's\npredictions, it achieved an F1-score of 0.855 (precision = 0.805, recall =\n0.914) for the \"age\" class. When it was evaluated directly on the held-out test\nset, it achieved an F1-score of 0.931 (precision = 0.873, recall = 0.998) for\nthe \"age\" class. We deployed ReportAGE on more than 1.2 billion tweets posted\nby 245,927 users, and predicted ages for 132,637 (54%) of them. Scaling the\ndetection of exact age to this large number of users can advance the utility of\nsocial media data for research applications that do not align with the\npredefined age groupings of extant binary or multi-class classification\napproaches.\n"
    },
    {
        "title": "Self-supervised Text-to-SQL Learning with Header Alignment Training",
        "summary": "  Since we can leverage a large amount of unlabeled data without any human\nsupervision to train a model and transfer the knowledge to target tasks,\nself-supervised learning is a de-facto component for the recent success of deep\nlearning in various fields. However, in many cases, there is a discrepancy\nbetween a self-supervised learning objective and a task-specific objective. In\norder to tackle such discrepancy in Text-to-SQL task, we propose a novel\nself-supervised learning framework. We utilize the task-specific properties of\nText-to-SQL task and the underlying structures of table contents to train the\nmodels to learn useful knowledge of the \\textit{header-column} alignment task\nfrom unlabeled table data. We are able to transfer the knowledge to the\nsupervised Text-to-SQL training with annotated samples, so that the model can\nleverage the knowledge to better perform the \\textit{header-span} alignment\ntask to predict SQL statements. Experimental results show that our\nself-supervised learning framework significantly improves the performance of\nthe existing strong BERT based models without using large external corpora. In\nparticular, our method is effective for training the model with scarce labeled\ndata. The source code of this work is available in GitHub.\n"
    },
    {
        "title": "MediaSum: A Large-scale Media Interview Dataset for Dialogue\n  Summarization",
        "summary": "  MediaSum, a large-scale media interview dataset consisting of 463.6K\ntranscripts with abstractive summaries. To create this dataset, we collect\ninterview transcripts from NPR and CNN and employ the overview and topic\ndescriptions as summaries. Compared with existing public corpora for dialogue\nsummarization, our dataset is an order of magnitude larger and contains complex\nmulti-party conversations from multiple domains. We conduct statistical\nanalysis to demonstrate the unique positional bias exhibited in the transcripts\nof televised and radioed interviews. We also show that MediaSum can be used in\ntransfer learning to improve a model's performance on other dialogue\nsummarization tasks.\n"
    },
    {
        "title": "LightMBERT: A Simple Yet Effective Method for Multilingual BERT\n  Distillation",
        "summary": "  The multilingual pre-trained language models (e.g, mBERT, XLM and XLM-R) have\nshown impressive performance on cross-lingual natural language understanding\ntasks. However, these models are computationally intensive and difficult to be\ndeployed on resource-restricted devices. In this paper, we propose a simple yet\neffective distillation method (LightMBERT) for transferring the cross-lingual\ngeneralization ability of the multilingual BERT to a small student model. The\nexperiment results empirically demonstrate the efficiency and effectiveness of\nLightMBERT, which is significantly better than the baselines and performs\ncomparable to the teacher mBERT.\n"
    },
    {
        "title": "Conversational Answer Generation and Factuality for Reading\n  Comprehension Question-Answering",
        "summary": "  Question answering (QA) is an important use case on voice assistants. A\npopular approach to QA is extractive reading comprehension (RC) which finds an\nanswer span in a text passage. However, extractive answers are often unnatural\nin a conversational context which results in suboptimal user experience. In\nthis work, we investigate conversational answer generation for QA. We propose\nAnswerBART, an end-to-end generative RC model which combines answer generation\nfrom multiple passages with passage ranking and answerability. Moreover, a\nhurdle in applying generative RC are hallucinations where the answer is\nfactually inconsistent with the passage text. We leverage recent work from\nsummarization to evaluate factuality. Experiments show that AnswerBART\nsignificantly improves over previous best published results on MS MARCO 2.1\nNLGEN by 2.5 ROUGE-L and NarrativeQA by 9.4 ROUGE-L.\n"
    },
    {
        "title": "Does the Magic of BERT Apply to Medical Code Assignment? A Quantitative\n  Study",
        "summary": "  Unsupervised pretraining is an integral part of many natural language\nprocessing systems, and transfer learning with language models has achieved\nremarkable results in many downstream tasks. In the clinical application of\nmedical code assignment, diagnosis and procedure codes are inferred from\nlengthy clinical notes such as hospital discharge summaries. However, it is not\nclear if pretrained models are useful for medical code prediction without\nfurther architecture engineering. This paper conducts a comprehensive\nquantitative analysis of various contextualized language models' performance,\npretrained in different domains, for medical code assignment from clinical\nnotes. We propose a hierarchical fine-tuning architecture to capture\ninteractions between distant words and adopt label-wise attention to exploit\nlabel information. Contrary to current trends, we demonstrate that a carefully\ntrained classical CNN outperforms attention-based models on a MIMIC-III subset\nwith frequent codes. Our empirical findings suggest directions for improving\nthe medical code assignment application.\n"
    },
    {
        "title": "DebIE: A Platform for Implicit and Explicit Debiasing of Word Embedding\n  Spaces",
        "summary": "  Recent research efforts in NLP have demonstrated that distributional word\nvector spaces often encode stereotypical human biases, such as racism and\nsexism. With word representations ubiquitously used in NLP models and\npipelines, this raises ethical issues and jeopardizes the fairness of language\ntechnologies. While there exists a large body of work on bias measures and\ndebiasing methods, to date, there is no platform that would unify these\nresearch efforts and make bias measuring and debiasing of representation spaces\nwidely accessible. In this work, we present DebIE, the first integrated\nplatform for (1) measuring and (2) mitigating bias in word embeddings. Given an\n(i) embedding space (users can choose between the predefined spaces or upload\ntheir own) and (ii) a bias specification (users can choose between existing\nbias specifications or create their own), DebIE can (1) compute several\nmeasures of implicit and explicit bias and modify the embedding space by\nexecuting two (mutually composable) debiasing models. DebIE's functionality can\nbe accessed through four different interfaces: (a) a web application, (b) a\ndesktop application, (c) a REST-ful API, and (d) as a command-line application.\nDebIE is available at: debie.informatik.uni-mannheim.de.\n"
    },
    {
        "title": "ASAP: A Chinese Review Dataset Towards Aspect Category Sentiment\n  Analysis and Rating Prediction",
        "summary": "  Sentiment analysis has attracted increasing attention in e-commerce. The\nsentiment polarities underlying user reviews are of great value for business\nintelligence. Aspect category sentiment analysis (ACSA) and review rating\nprediction (RP) are two essential tasks to detect the fine-to-coarse sentiment\npolarities. %Considering the sentiment of the aspects(ACSA) and the overall\nreview rating(RP) simultaneously has the potential to improve the overall\nperformance. ACSA and RP are highly correlated and usually employed jointly in\nreal-world e-commerce scenarios. While most public datasets are constructed for\nACSA and RP separately, which may limit the further exploitation of both tasks.\nTo address the problem and advance related researches, we present a large-scale\nChinese restaurant review dataset \\textbf{ASAP} including $46,730$ genuine\nreviews from a leading online-to-offline (O2O) e-commerce platform in China.\nBesides a $5$-star scale rating, each review is manually annotated according to\nits sentiment polarities towards $18$ pre-defined aspect categories. We hope\nthe release of the dataset could shed some light on the fields of sentiment\nanalysis. Moreover, we propose an intuitive yet effective joint model for ACSA\nand RP. Experimental results demonstrate that the joint model outperforms\nstate-of-the-art baselines on both tasks.\n"
    },
    {
        "title": "Domain State Tracking for a Simplified Dialogue System",
        "summary": "  Task-oriented dialogue systems aim to help users achieve their goals in\nspecific domains. Recent neural dialogue systems use the entire dialogue\nhistory for abundant contextual information accumulated over multiple\nconversational turns. However, the dialogue history becomes increasingly longer\nas the number of turns increases, thereby increasing memory usage and\ncomputational costs. In this paper, we present DoTS (Domain State Tracking for\na Simplified Dialogue System), a task-oriented dialogue system that uses a\nsimplified input context instead of the entire dialogue history. However,\nneglecting the dialogue history can result in a loss of contextual information\nfrom previous conversational turns. To address this issue, DoTS tracks the\ndomain state in addition to the belief state and uses it for the input context.\nUsing this simplified input, DoTS improves the inform rate and success rate by\n1.09 points and 1.24 points, respectively, compared to the previous\nstate-of-the-art model on MultiWOZ, which is a well-known benchmark.\n"
    },
    {
        "title": "The Interplay of Variant, Size, and Task Type in Arabic Pre-trained\n  Language Models",
        "summary": "  In this paper, we explore the effects of language variants, data sizes, and\nfine-tuning task types in Arabic pre-trained language models. To do so, we\nbuild three pre-trained language models across three variants of Arabic: Modern\nStandard Arabic (MSA), dialectal Arabic, and classical Arabic, in addition to a\nfourth language model which is pre-trained on a mix of the three. We also\nexamine the importance of pre-training data size by building additional models\nthat are pre-trained on a scaled-down set of the MSA variant. We compare our\ndifferent models to each other, as well as to eight publicly available models\nby fine-tuning them on five NLP tasks spanning 12 datasets. Our results suggest\nthat the variant proximity of pre-training data to fine-tuning data is more\nimportant than the pre-training data size. We exploit this insight in defining\nan optimized system selection model for the studied tasks.\n"
    },
    {
        "title": "Unsupervised Transfer Learning in Multilingual Neural Machine\n  Translation with Cross-Lingual Word Embeddings",
        "summary": "  In this work we look into adding a new language to a multilingual NMT system\nin an unsupervised fashion. Under the utilization of pre-trained cross-lingual\nword embeddings we seek to exploit a language independent multilingual sentence\nrepresentation to easily generalize to a new language. While using\ncross-lingual embeddings for word lookup we decode from a yet entirely unseen\nsource language in a process we call blind decoding. Blindly decoding from\nPortuguese using a basesystem containing several Romance languages we achieve\nscores of 36.4 BLEU for Portuguese-English and 12.8 BLEU for Russian-English.\nIn an attempt to train the mapping from the encoder sentence representation to\na new target language we use our model as an autoencoder. Merely training to\ntranslate from Portuguese to Portuguese while freezing the encoder we achieve\n26 BLEU on English-Portuguese, and up to 28 BLEU when adding artificial noise\nto the input. Lastly we explore a more practical adaptation approach through\nnon-iterative backtranslation, exploiting our model's ability to produce high\nquality translations through blind decoding. This yields us up to 34.6 BLEU on\nEnglish-Portuguese, attaining near parity with a model adapted on real\nbilingual data.\n"
    },
    {
        "title": "MERMAID: Metaphor Generation with Symbolism and Discriminative Decoding",
        "summary": "  Generating metaphors is a challenging task as it requires a proper\nunderstanding of abstract concepts, making connections between unrelated\nconcepts, and deviating from the literal meaning. In this paper, we aim to\ngenerate a metaphoric sentence given a literal expression by replacing relevant\nverbs. Based on a theoretically-grounded connection between metaphors and\nsymbols, we propose a method to automatically construct a parallel corpus by\ntransforming a large number of metaphorical sentences from the Gutenberg Poetry\ncorpus (Jacobs, 2018) to their literal counterpart using recent advances in\nmasked language modeling coupled with commonsense inference. For the generation\ntask, we incorporate a metaphor discriminator to guide the decoding of a\nsequence to sequence model fine-tuned on our parallel data to generate\nhigh-quality metaphors. Human evaluation on an independent test set of literal\nstatements shows that our best model generates metaphors better than three\nwell-crafted baselines 66% of the time on average. A task-based evaluation\nshows that human-written poems enhanced with metaphors proposed by our model\nare preferred 68% of the time compared to poems without metaphors.\n"
    },
    {
        "title": "Towards Continual Learning for Multilingual Machine Translation via\n  Vocabulary Substitution",
        "summary": "  We propose a straightforward vocabulary adaptation scheme to extend the\nlanguage capacity of multilingual machine translation models, paving the way\ntowards efficient continual learning for multilingual machine translation. Our\napproach is suitable for large-scale datasets, applies to distant languages\nwith unseen scripts, incurs only minor degradation on the translation\nperformance for the original language pairs and provides competitive\nperformance even in the case where we only possess monolingual data for the new\nlanguages.\n"
    },
    {
        "title": "Evaluation of Morphological Embeddings for English and Russian Languages",
        "summary": "  This paper evaluates morphology-based embeddings for English and Russian\nlanguages. Despite the interest and introduction of several morphology-based\nword embedding models in the past and acclaimed performance improvements on\nword similarity and language modeling tasks, in our experiments, we did not\nobserve any stable preference over two of our baseline models - SkipGram and\nFastText. The performance exhibited by morphological embeddings is the average\nof the two baselines mentioned above.\n"
    },
    {
        "title": "Anaphoric Binding: an integrated overview",
        "summary": "  The interpretation of anaphors depends on their antecedents as the semantic\nvalue that an anaphor eventually conveys is co-specified by the value of its\nantecedent. Interestingly, when occurring in a given syntactic position,\ndifferent anaphors may have different sets of admissible antecedents. Such\ndifferences are the basis for the categorization of anaphoric expressions\naccording to their anaphoric capacity, being important to determine what are\nthe sets of admissible antecedents and how to represent and process this\nanaphoric capacity for each type of anaphor.\n  From an empirical perspective, these constraints stem from what appears as\nquite cogent generalisations and exhibit a universal character, given their\ncross linguistic validity. From a conceptual point of view, in turn, the\nrelations among binding constraints involve non-trivial cross symmetry, which\nlends them a modular nature and provides further strength to the plausibility\nof their universal character. This kind of anaphoric binding constraints\nappears thus as a most significant subset of natural language knowledge,\nusually referred to as binding theory.\n  This paper provides an integrated overview of these constraints holding on\nthe pairing of nominal anaphors with their admissible antecedents that are\nbased on grammatical relations and structure. Along with the increasing\ninterest on neuro-symbolic approaches to natural language, this paper seeks to\ncontribute to revive the interest on this most intriguing research topic.\n"
    },
    {
        "title": "Preregistering NLP Research",
        "summary": "  Preregistration refers to the practice of specifying what you are going to\ndo, and what you expect to find in your study, before carrying out the study.\nThis practice is increasingly common in medicine and psychology, but is rarely\ndiscussed in NLP. This paper discusses preregistration in more detail, explores\nhow NLP researchers could preregister their work, and presents several\npreregistration questions for different kinds of studies. Finally, we argue in\nfavour of registered reports, which could provide firmer grounds for slow\nscience in NLP research. The goal of this paper is to elicit a discussion in\nthe NLP community, which we hope to synthesise into a general NLP\npreregistration form in future research.\n"
    },
    {
        "title": "Learning Policies for Multilingual Training of Neural Machine\n  Translation Systems",
        "summary": "  Low-resource Multilingual Neural Machine Translation (MNMT) is typically\ntasked with improving the translation performance on one or more language pairs\nwith the aid of high-resource language pairs. In this paper, we propose two\nsimple search based curricula -- orderings of the multilingual training data --\nwhich help improve translation performance in conjunction with existing\ntechniques such as fine-tuning. Additionally, we attempt to learn a curriculum\nfor MNMT from scratch jointly with the training of the translation system with\nthe aid of contextual multi-arm bandits. We show on the FLORES low-resource\ntranslation dataset that these learned curricula can provide better starting\npoints for fine tuning and improve overall performance of the translation\nsystem.\n"
    },
    {
        "title": "Learning Feature Weights using Reward Modeling for Denoising Parallel\n  Corpora",
        "summary": "  Large web-crawled corpora represent an excellent resource for improving the\nperformance of Neural Machine Translation (NMT) systems across several language\npairs. However, since these corpora are typically extremely noisy, their use is\nfairly limited. Current approaches to dealing with this problem mainly focus on\nfiltering using heuristics or single features such as language model scores or\nbi-lingual similarity. This work presents an alternative approach which learns\nweights for multiple sentence-level features. These feature weights which are\noptimized directly for the task of improving translation performance, are used\nto score and filter sentences in the noisy corpora more effectively. We provide\nresults of applying this technique to building NMT systems using the Paracrawl\ncorpus for Estonian-English and show that it beats strong single feature\nbaselines and hand designed combinations. Additionally, we analyze the\nsensitivity of this method to different types of noise and explore if the\nlearned weights generalize to other language pairs using the Maltese-English\nParacrawl corpus.\n"
    },
    {
        "title": "Inductive Relation Prediction by BERT",
        "summary": "  Relation prediction in knowledge graphs is dominated by embedding based\nmethods which mainly focus on the transductive setting. Unfortunately, they are\nnot able to handle inductive learning where unseen entities and relations are\npresent and cannot take advantage of prior knowledge. Furthermore, their\ninference process is not easily explainable. In this work, we propose an\nall-in-one solution, called BERTRL (BERT-based Relational Learning), which\nleverages pre-trained language model and fine-tunes it by taking relation\ninstances and their possible reasoning paths as training samples. BERTRL\noutperforms the SOTAs in 15 out of 18 cases in both inductive and transductive\nsettings. Meanwhile, it demonstrates strong generalization capability in\nfew-shot learning and is explainable.\n"
    },
    {
        "title": "Constrained Text Generation with Global Guidance -- Case Study on\n  CommonGen",
        "summary": "  This paper studies constrained text generation, which is to generate\nsentences under certain pre-conditions. We focus on CommonGen, the task of\ngenerating text based on a set of concepts, as a representative task of\nconstrained text generation. Traditional methods mainly rely on supervised\ntraining to maximize the likelihood of target sentences.However, global\nconstraints such as common sense and coverage cannot be incorporated into the\nlikelihood objective of the autoregressive decoding process. In this paper, we\nconsider using reinforcement learning to address the limitation, measuring\nglobal constraints including fluency, common sense and concept coverage with a\ncomprehensive score, which serves as the reward for reinforcement learning.\nBesides, we design a guided decoding method at the word, fragment and sentence\nlevels. Experiments demonstrate that our method significantly increases the\nconcept coverage and outperforms existing models in various automatic\nevaluations.\n"
    },
    {
        "title": "Are NLP Models really able to Solve Simple Math Word Problems?",
        "summary": "  The problem of designing NLP solvers for math word problems (MWP) has seen\nsustained research activity and steady gains in the test accuracy. Since\nexisting solvers achieve high performance on the benchmark datasets for\nelementary level MWPs containing one-unknown arithmetic word problems, such\nproblems are often considered \"solved\" with the bulk of research attention\nmoving to more complex MWPs. In this paper, we restrict our attention to\nEnglish MWPs taught in grades four and lower. We provide strong evidence that\nthe existing MWP solvers rely on shallow heuristics to achieve high performance\non the benchmark datasets. To this end, we show that MWP solvers that do not\nhave access to the question asked in the MWP can still solve a large fraction\nof MWPs. Similarly, models that treat MWPs as bag-of-words can also achieve\nsurprisingly high accuracy. Further, we introduce a challenge dataset, SVAMP,\ncreated by applying carefully chosen variations over examples sampled from\nexisting datasets. The best accuracy achieved by state-of-the-art models is\nsubstantially lower on SVAMP, thus showing that much remains to be done even\nfor the simplest of the MWPs.\n"
    },
    {
        "title": "Automatic Romanization of Arabic Bibliographic Records",
        "summary": "  International library standards require cataloguers to tediously input\nRomanization of their catalogue records for the benefit of library users\nwithout specific language expertise. In this paper, we present the first\nreported results on the task of automatic Romanization of undiacritized Arabic\nbibliographic entries. This complex task requires the modeling of Arabic\nphonology, morphology, and even semantics. We collected a 2.5M word corpus of\nparallel Arabic and Romanized bibliographic entries, and benchmarked a number\nof models that vary in terms of complexity and resource dependence. Our best\nsystem reaches 89.3% exact word Romanization on a blind test set. We make our\ndata and code publicly available.\n"
    },
    {
        "title": "Explaining and Improving BERT Performance on Lexical Semantic Change\n  Detection",
        "summary": "  Type- and token-based embedding architectures are still competing in lexical\nsemantic change detection. The recent success of type-based models in\nSemEval-2020 Task 1 has raised the question why the success of token-based\nmodels on a variety of other NLP tasks does not translate to our field. We\ninvestigate the influence of a range of variables on clusterings of BERT\nvectors and show that its low performance is largely due to orthographic\ninformation on the target word, which is encoded even in the higher layers of\nBERT representations. By reducing the influence of orthography we considerably\nimprove BERT's performance.\n"
    },
    {
        "title": "A Simple Post-Processing Technique for Improving Readability Assessment\n  of Texts using Word Mover's Distance",
        "summary": "  Assessing the proper difficulty levels of reading materials or texts in\ngeneral is the first step towards effective comprehension and learning. In this\nstudy, we improve the conventional methodology of automatic readability\nassessment by incorporating the Word Mover's Distance (WMD) of ranked texts as\nan additional post-processing technique to further ground the difficulty level\ngiven by a model. Results of our experiments on three multilingual datasets in\nFilipino, German, and English show that the post-processing technique\noutperforms previous vanilla and ranking-based models using SVM.\n"
    },
    {
        "title": "Visual Cues and Error Correction for Translation Robustness",
        "summary": "  Neural Machine Translation models are sensitive to noise in the input texts,\nsuch as misspelled words and ungrammatical constructions. Existing robustness\ntechniques generally fail when faced with unseen types of noise and their\nperformance degrades on clean texts. In this paper, we focus on three types of\nrealistic noise that are commonly generated by humans and introduce the idea of\nvisual context to improve translation robustness for noisy texts. In addition,\nwe describe a novel error correction training regime that can be used as an\nauxiliary task to further improve translation robustness. Experiments on\nEnglish-French and English-German translation show that both multimodal and\nerror correction components improve model robustness to noisy texts, while\nstill retaining translation quality on clean texts.\n"
    },
    {
        "title": "Few-Shot Text Classification with Triplet Networks, Data Augmentation,\n  and Curriculum Learning",
        "summary": "  Few-shot text classification is a fundamental NLP task in which a model aims\nto classify text into a large number of categories, given only a few training\nexamples per category. This paper explores data augmentation -- a technique\nparticularly suitable for training with limited data -- for this few-shot,\nhighly-multiclass text classification setting. On four diverse text\nclassification tasks, we find that common data augmentation techniques can\nimprove the performance of triplet networks by up to 3.0% on average.\n  To further boost performance, we present a simple training strategy called\ncurriculum data augmentation, which leverages curriculum learning by first\ntraining on only original examples and then introducing augmented data as\ntraining progresses. We explore a two-stage and a gradual schedule, and find\nthat, compared with standard single-stage training, curriculum data\naugmentation trains faster, improves performance, and remains robust to high\namounts of noising from augmentation.\n"
    },
    {
        "title": "Improving Diversity of Neural Text Generation via Inverse Probability\n  Weighting",
        "summary": "  The neural text generation suffers from the text degeneration issue such as\nrepetition. Traditional stochastic sampling methods only focus on truncating\nthe unreliable \"tail\" of the distribution, and do not address the \"head\" part,\nwhich we show might contain tedious or even repetitive candidates with high\nprobability that lead to repetition loops. They also do not consider the issue\nthat human text does not always favor high-probability words. Inspired by\nthese, in this work we propose a heuristic sampling method. We propose to use\ninterquartile range of the predicted distribution to determine the \"head\" part,\nthen permutate and rescale the \"head\" with inverse probability. This aims at\ndecreasing the probability for the tedious and possibly repetitive candidates\nwith higher probability, and increasing the probability for the rational but\nmore surprising candidates with lower probability. The proposed algorithm\nprovides a reasonable permutation on the predicted distribution which enhances\ndiversity without compromising rationality of the distribution. We use\npre-trained language model to compare our algorithm with traditional methods.\nResults show that our algorithm can effectively increase the diversity of\ngenerated samples while achieving close resemblance to human text.\n"
    },
    {
        "title": "Bidirectional Machine Reading Comprehension for Aspect Sentiment Triplet\n  Extraction",
        "summary": "  Aspect sentiment triplet extraction (ASTE), which aims to identify aspects\nfrom review sentences along with their corresponding opinion expressions and\nsentiments, is an emerging task in fine-grained opinion mining. Since ASTE\nconsists of multiple subtasks, including opinion entity extraction, relation\ndetection, and sentiment classification, it is critical and challenging to\nappropriately capture and utilize the associations among them. In this paper,\nwe transform ASTE task into a multi-turn machine reading comprehension (MTMRC)\ntask and propose a bidirectional MRC (BMRC) framework to address this\nchallenge. Specifically, we devise three types of queries, including\nnon-restrictive extraction queries, restrictive extraction queries and\nsentiment classification queries, to build the associations among different\nsubtasks. Furthermore, considering that an aspect sentiment triplet can derive\nfrom either an aspect or an opinion expression, we design a bidirectional MRC\nstructure. One direction sequentially recognizes aspects, opinion expressions,\nand sentiments to obtain triplets, while the other direction identifies opinion\nexpressions first, then aspects, and at last sentiments. By making the two\ndirections complement each other, our framework can identify triplets more\ncomprehensively. To verify the effectiveness of our approach, we conduct\nextensive experiments on four benchmark datasets. The experimental results\ndemonstrate that BMRC achieves state-of-the-art performances.\n"
    },
    {
        "title": "Context Transformer with Stacked Pointer Networks for Conversational\n  Question Answering over Knowledge Graphs",
        "summary": "  Neural semantic parsing approaches have been widely used for Question\nAnswering (QA) systems over knowledge graphs. Such methods provide the\nflexibility to handle QA datasets with complex queries and a large number of\nentities. In this work, we propose a novel framework named CARTON, which\nperforms multi-task semantic parsing for handling the problem of conversational\nquestion answering over a large-scale knowledge graph. Our framework consists\nof a stack of pointer networks as an extension of a context transformer model\nfor parsing the input question and the dialog history. The framework generates\na sequence of actions that can be executed on the knowledge graph. We evaluate\nCARTON on a standard dataset for complex sequential question answering on which\nCARTON outperforms all baselines. Specifically, we observe performance\nimprovements in F1-score on eight out of ten question types compared to the\nprevious state of the art. For logical reasoning questions, an improvement of\n11 absolute points is reached.\n"
    },
    {
        "title": "ParaQA: A Question Answering Dataset with Paraphrase Responses for\n  Single-Turn Conversation",
        "summary": "  This paper presents ParaQA, a question answering (QA) dataset with multiple\nparaphrased responses for single-turn conversation over knowledge graphs (KG).\nThe dataset was created using a semi-automated framework for generating diverse\nparaphrasing of the answers using techniques such as back-translation. The\nexisting datasets for conversational question answering over KGs\n(single-turn/multi-turn) focus on question paraphrasing and provide only up to\none answer verbalization. However, ParaQA contains 5000 question-answer pairs\nwith a minimum of two and a maximum of eight unique paraphrased responses for\neach question. We complement the dataset with baseline models and illustrate\nthe advantage of having multiple paraphrased answers through commonly used\nmetrics such as BLEU and METEOR. The ParaQA dataset is publicly available on a\npersistent URI for broader usage and adaptation in the research community.\n"
    },
    {
        "title": "Deep Discourse Analysis for Generating Personalized Feedback in\n  Intelligent Tutor Systems",
        "summary": "  We explore creating automated, personalized feedback in an intelligent\ntutoring system (ITS). Our goal is to pinpoint correct and incorrect concepts\nin student answers in order to achieve better student learning gains. Although\nautomatic methods for providing personalized feedback exist, they do not\nexplicitly inform students about which concepts in their answers are correct or\nincorrect. Our approach involves decomposing students answers using neural\ndiscourse segmentation and classification techniques. This decomposition yields\na relational graph over all discourse units covered by the reference solutions\nand student answers. We use this inferred relational graph structure and a\nneural classifier to match student answers with reference solutions and\ngenerate personalized feedback. Although the process is completely automated\nand data-driven, the personalized feedback generated is highly contextual,\ndomain-aware and effectively targets each student's misconceptions and\nknowledge gaps. We test our method in a dialogue-based ITS and demonstrate that\nour approach results in high-quality feedback and significantly improved\nstudent learning gains.\n"
    },
    {
        "title": "SemVLP: Vision-Language Pre-training by Aligning Semantics at Multiple\n  Levels",
        "summary": "  Vision-language pre-training (VLP) on large-scale image-text pairs has\nrecently witnessed rapid progress for learning cross-modal representations.\nExisting pre-training methods either directly concatenate image representation\nand text representation at a feature level as input to a single-stream\nTransformer, or use a two-stream cross-modal Transformer to align the\nimage-text representation at a high-level semantic space. In real-world\nimage-text data, we observe that it is easy for some of the image-text pairs to\nalign simple semantics on both modalities, while others may be related after\nhigher-level abstraction. Therefore, in this paper, we propose a new\npre-training method SemVLP, which jointly aligns both the low-level and\nhigh-level semantics between image and text representations. The model is\npre-trained iteratively with two prevalent fashions: single-stream pre-training\nto align at a fine-grained feature level and two-stream pre-training to align\nhigh-level semantics, by employing a shared Transformer network with a\npluggable cross-modal attention module. An extensive set of experiments have\nbeen conducted on four well-established vision-language understanding tasks to\ndemonstrate the effectiveness of the proposed SemVLP in aligning cross-modal\nrepresentations towards different semantic granularities.\n"
    },
    {
        "title": "A `Sourceful' Twist: Emoji Prediction Based on Sentiment, Hashtags and\n  Application Source",
        "summary": "  We widely use emojis in social networking to heighten, mitigate or negate the\nsentiment of the text. Emoji suggestions already exist in many cross-platform\napplications but an emoji is predicted solely based a few prominent words\ninstead of understanding the subject and substance of the text. Through this\npaper, we showcase the importance of using Twitter features to help the model\nunderstand the sentiment involved and hence to predict the most suitable emoji\nfor the text. Hashtags and Application Sources like Android, etc. are two\nfeatures which we found to be important yet underused in emoji prediction and\nTwitter sentiment analysis on the whole. To approach this shortcoming and to\nfurther understand emoji behavioral patterns, we propose a more balanced\ndataset by crawling additional Twitter data, including timestamp, hashtags, and\napplication source acting as additional attributes to the tweet. Our data\nanalysis and neural network model performance evaluations depict that using\nhashtags and application sources as features allows to encode different\ninformation and is effective in emoji prediction.\n"
    },
    {
        "title": "Learning a Word-Level Language Model with Sentence-Level Noise\n  Contrastive Estimation for Contextual Sentence Probability Estimation",
        "summary": "  Inferring the probability distribution of sentences or word sequences is a\nkey process in natural language processing. While word-level language models\n(LMs) have been widely adopted for computing the joint probabilities of word\nsequences, they have difficulty in capturing a context long enough for sentence\nprobability estimation (SPE). To overcome this, recent studies introduced\ntraining methods using sentence-level noise-contrastive estimation (NCE) with\nrecurrent neural networks (RNNs). In this work, we attempt to extend it for\ncontextual SPE, which aims to estimate a conditional sentence probability given\na previous text. The proposed NCE samples negative sentences independently of a\nprevious text so that the trained model gives higher probabilities to the\nsentences that are more consistent with \\textcolor{blue}{the} context. We apply\nour method to a simple word-level RNN LM to focus on the effect of the\nsentence-level NCE training rather than on the network architecture. The\nquality of estimation was evaluated against multiple-choice cloze-style\nquestions including both human and automatically generated questions. The\nexperimental results show that the proposed method improved the SPE quality for\nthe word-level RNN LM.\n"
    },
    {
        "title": "A Systematic Review of Reproducibility Research in Natural Language\n  Processing",
        "summary": "  Against the background of what has been termed a reproducibility crisis in\nscience, the NLP field is becoming increasingly interested in, and\nconscientious about, the reproducibility of its results. The past few years\nhave seen an impressive range of new initiatives, events and active research in\nthe area. However, the field is far from reaching a consensus about how\nreproducibility should be defined, measured and addressed, with diversity of\nviews currently increasing rather than converging. With this focused\ncontribution, we aim to provide a wide-angle, and as near as possible complete,\nsnapshot of current work on reproducibility in NLP, delineating differences and\nsimilarities, and providing pointers to common denominators.\n"
    },
    {
        "title": "Generating CCG Categories",
        "summary": "  Previous CCG supertaggers usually predict categories using multi-class\nclassification. Despite their simplicity, internal structures of categories are\nusually ignored. The rich semantics inside these structures may help us to\nbetter handle relations among categories and bring more robustness into\nexisting supertaggers. In this work, we propose to generate categories rather\nthan classify them: each category is decomposed into a sequence of smaller\natomic tags, and the tagger aims to generate the correct sequence. We show that\nwith this finer view on categories, annotations of different categories could\nbe shared and interactions with sentence contexts could be enhanced. The\nproposed category generator is able to achieve state-of-the-art tagging (95.5%\naccuracy) and parsing (89.8% labeled F1) performances on the standard CCGBank.\nFurthermore, its performances on infrequent (even unseen) categories,\nout-of-domain texts and low resource language give promising results on\nintroducing generation models to the general CCG analyses.\n"
    },
    {
        "title": "Towards the evaluation of automatic simultaneous speech translation from\n  a communicative perspective",
        "summary": "  In recent years, automatic speech-to-speech and speech-to-text translation\nhas gained momentum thanks to advances in artificial intelligence, especially\nin the domains of speech recognition and machine translation. The quality of\nsuch applications is commonly tested with automatic metrics, such as BLEU,\nprimarily with the goal of assessing improvements of releases or in the context\nof evaluation campaigns. However, little is known about how the output of such\nsystems is perceived by end users or how they compare to human performances in\nsimilar communicative tasks.\n  In this paper, we present the results of an experiment aimed at evaluating\nthe quality of a real-time speech translation engine by comparing it to the\nperformance of professional simultaneous interpreters. To do so, we adopt a\nframework developed for the assessment of human interpreters and use it to\nperform a manual evaluation on both human and machine performances. In our\nsample, we found better performance for the human interpreters in terms of\nintelligibility, while the machine performs slightly better in terms of\ninformativeness. The limitations of the study and the possible enhancements of\nthe chosen framework are discussed. Despite its intrinsic limitations, the use\nof this framework represents a first step towards a user-centric and\ncommunication-oriented methodology for evaluating real-time automatic speech\ntranslation.\n"
    },
    {
        "title": "NADI 2021: The Second Nuanced Arabic Dialect Identification Shared Task",
        "summary": "  We present the findings and results of the Second Nuanced Arabic Dialect\nIdentification Shared Task (NADI 2021). This Shared Task includes four\nsubtasks: country-level Modern Standard Arabic (MSA) identification (Subtask\n1.1), country-level dialect identification (Subtask 1.2), province-level MSA\nidentification (Subtask 2.1), and province-level sub-dialect identification\n(Subtask 2.2). The shared task dataset covers a total of 100 provinces from 21\nArab countries, collected from the Twitter domain. A total of 53 teams from 23\ncountries registered to participate in the tasks, thus reflecting the interest\nof the community in this area. We received 16 submissions for Subtask 1.1 from\nfive teams, 27 submissions for Subtask 1.2 from eight teams, 12 submissions for\nSubtask 2.1 from four teams, and 13 Submissions for subtask 2.2 from four\nteams.\n"
    },
    {
        "title": "Multi-view Subword Regularization",
        "summary": "  Multilingual pretrained representations generally rely on subword\nsegmentation algorithms to create a shared multilingual vocabulary. However,\nstandard heuristic algorithms often lead to sub-optimal segmentation,\nespecially for languages with limited amounts of data. In this paper, we take\ntwo major steps towards alleviating this problem. First, we demonstrate\nempirically that applying existing subword regularization methods(Kudo, 2018;\nProvilkov et al., 2020) during fine-tuning of pre-trained multilingual\nrepresentations improves the effectiveness of cross-lingual transfer. Second,\nto take full advantage of different possible input segmentations, we propose\nMulti-view Subword Regularization (MVR), a method that enforces the consistency\nbetween predictions of using inputs tokenized by the standard and probabilistic\nsegmentations. Results on the XTREME multilingual benchmark(Hu et al., 2020)\nshow that MVR brings consistent improvements of up to 2.5 points over using\nstandard segmentation algorithms.\n"
    },
    {
        "title": "The Effect of Domain and Diacritics in Yor\u00f9b\u00e1-English Neural Machine\n  Translation",
        "summary": "  Massively multilingual machine translation (MT) has shown impressive\ncapabilities, including zero and few-shot translation between low-resource\nlanguage pairs. However, these models are often evaluated on high-resource\nlanguages with the assumption that they generalize to low-resource ones. The\ndifficulty of evaluating MT models on low-resource pairs is often due to lack\nof standardized evaluation datasets. In this paper, we present MENYO-20k, the\nfirst multi-domain parallel corpus with a special focus on clean orthography\nfor Yor\\`ub\\'a--English with standardized train-test splits for benchmarking.\nWe provide several neural MT benchmarks and compare them to the performance of\npopular pre-trained (massively multilingual) MT models both for the\nheterogeneous test set and its subdomains. Since these pre-trained models use\nhuge amounts of data with uncertain quality, we also analyze the effect of\ndiacritics, a major characteristic of Yor\\`ub\\'a, in the training data. We\ninvestigate how and when this training condition affects the final quality and\nintelligibility of a translation. Our models outperform massively multilingual\nmodels such as Google ($+8.7$ BLEU) and Facebook M2M ($+9.1$ BLEU) when\ntranslating to Yor\\`ub\\'a, setting a high quality benchmark for future\nresearch.\n"
    },
    {
        "title": "A Transition-based Parser for Unscoped Episodic Logical Forms",
        "summary": "  \"Episodic Logic:Unscoped Logical Form\" (EL-ULF) is a semantic representation\ncapturing predicate-argument structure as well as more challenging aspects of\nlanguage within the Episodic Logic formalism. We present the first learned\napproach for parsing sentences into ULFs, using a growing set of annotated\nexamples. The results provide a strong baseline for future improvement. Our\nmethod learns a sequence-to-sequence model for predicting the transition action\nsequence within a modified cache transition system. We evaluate the efficacy of\ntype grammar-based constraints, a word-to-symbol lexicon, and transition system\nstate features in this task. Our system is available at\nhttps://github.com/genelkim/ulf-transition-parser We also present the first\nofficial annotated ULF dataset at\nhttps://www.cs.rochester.edu/u/gkim21/ulf/resources/.\n"
    },
    {
        "title": "Robustly Optimized and Distilled Training for Natural Language\n  Understanding",
        "summary": "  In this paper, we explore multi-task learning (MTL) as a second pretraining\nstep to learn enhanced universal language representation for transformer\nlanguage models. We use the MTL enhanced representation across several natural\nlanguage understanding tasks to improve performance and generalization.\nMoreover, we incorporate knowledge distillation (KD) in MTL to further boost\nperformance and devise a KD variant that learns effectively from multiple\nteachers. By combining MTL and KD, we propose Robustly Optimized and Distilled\n(ROaD) modeling framework. We use ROaD together with the ELECTRA model to\nobtain state-of-the-art results for machine reading comprehension and natural\nlanguage inference.\n"
    },
    {
        "title": "Gumbel-Attention for Multi-modal Machine Translation",
        "summary": "  Multi-modal machine translation (MMT) improves translation quality by\nintroducing visual information. However, the existing MMT model ignores the\nproblem that the image will bring information irrelevant to the text, causing\nmuch noise to the model and affecting the translation quality. This paper\nproposes a novel Gumbel-Attention for multi-modal machine translation, which\nselects the text-related parts of the image features. Specifically, different\nfrom the previous attention-based method, we first use a differentiable method\nto select the image information and automatically remove the useless parts of\nthe image features. Experiments prove that our method retains the image\nfeatures related to the text, and the remaining parts help the MMT model\ngenerates better translations.\n"
    },
    {
        "title": "Coordinate Constructions in English Enhanced Universal Dependencies:\n  Analysis and Computational Modeling",
        "summary": "  In this paper, we address the representation of coordinate constructions in\nEnhanced Universal Dependencies (UD), where relevant dependency links are\npropagated from conjunction heads to other conjuncts. English treebanks for\nenhanced UD have been created from gold basic dependencies using a heuristic\nrule-based converter, which propagates only core arguments. With the aim of\ndetermining which set of links should be propagated from a semantic\nperspective, we create a large-scale dataset of manually edited syntax graphs.\nWe identify several systematic errors in the original data, and propose to also\npropagate adjuncts. We observe high inter-annotator agreement for this semantic\nannotation task. Using our new manually verified dataset, we perform the first\nprincipled comparison of rule-based and (partially novel) machine-learning\nbased methods for conjunction propagation for English. We show that learning\npropagation rules is more effective than hand-designing heuristic rules. When\nusing automatic parses, our neural graph-parser based edge predictor\noutperforms the currently predominant pipelinesusing a basic-layer tree parser\nplus converters.\n"
    },
    {
        "title": "Structural Adapters in Pretrained Language Models for AMR-to-text\n  Generation",
        "summary": "  Pretrained language models (PLM) have recently advanced graph-to-text\ngeneration, where the input graph is linearized into a sequence and fed into\nthe PLM to obtain its representation. However, efficiently encoding the graph\nstructure in PLMs is challenging because such models were pretrained on natural\nlanguage, and modeling structured data may lead to catastrophic forgetting of\ndistributional knowledge. In this paper, we propose StructAdapt, an adapter\nmethod to encode graph structure into PLMs. Contrary to prior work, StructAdapt\neffectively models interactions among the nodes based on the graph\nconnectivity, only training graph structure-aware adapter parameters. In this\nway, we incorporate task-specific knowledge while maintaining the topological\nstructure of the graph. We empirically show the benefits of explicitly encoding\ngraph structure into PLMs using StructAdapt, outperforming the state of the art\non two AMR-to-text datasets, training only 5.1% of the PLM parameters.\n"
    },
    {
        "title": "No Intruder, no Validity: Evaluation Criteria for Privacy-Preserving\n  Text Anonymization",
        "summary": "  For sensitive text data to be shared among NLP researchers and practitioners,\nshared documents need to comply with data protection and privacy laws. There is\nhence a growing interest in automated approaches for text anonymization.\nHowever, measuring such methods' performance is challenging: missing a single\nidentifying attribute can reveal an individual's identity. In this paper, we\ndraw attention to this problem and argue that researchers and practitioners\ndeveloping automated text anonymization systems should carefully assess whether\ntheir evaluation methods truly reflect the system's ability to protect\nindividuals from being re-identified. We then propose TILD, a set of evaluation\ncriteria that comprises an anonymization method's technical performance, the\ninformation loss resulting from its anonymization, and the human ability to\nde-anonymize redacted documents. These criteria may facilitate progress towards\na standardized way for measuring anonymization performance.\n"
    },
    {
        "title": "Cross-Task Instance Representation Interactions and Label Dependencies\n  for Joint Information Extraction with Graph Convolutional Networks",
        "summary": "  Existing works on information extraction (IE) have mainly solved the four\nmain tasks separately (entity mention recognition, relation extraction, event\ntrigger detection, and argument extraction), thus failing to benefit from\ninter-dependencies between tasks. This paper presents a novel deep learning\nmodel to simultaneously solve the four tasks of IE in a single model (called\nFourIE). Compared to few prior work on jointly performing four IE tasks, FourIE\nfeatures two novel contributions to capture inter-dependencies between tasks.\nFirst, at the representation level, we introduce an interaction graph between\ninstances of the four tasks that is used to enrich the prediction\nrepresentation for one instance with those from related instances of other\ntasks. Second, at the label level, we propose a dependency graph for the\ninformation types in the four IE tasks that captures the connections between\nthe types expressed in an input sentence. A new regularization mechanism is\nintroduced to enforce the consistency between the golden and predicted type\ndependency graphs to improve representation learning. We show that the proposed\nmodel achieves the state-of-the-art performance for joint IE on both\nmonolingual and multilingual learning settings with three different languages.\n"
    },
    {
        "title": "Dialogue History Matters! Personalized Response Selectionin Multi-turn\n  Retrieval-based Chatbots",
        "summary": "  Existing multi-turn context-response matching methods mainly concentrate on\nobtaining multi-level and multi-dimension representations and better\ninteractions between context utterances and response. However, in real-place\nconversation scenarios, whether a response candidate is suitable not only\ncounts on the given dialogue context but also other backgrounds, e.g., wording\nhabits, user-specific dialogue history content. To fill the gap between these\nup-to-date methods and the real-world applications, we incorporate\nuser-specific dialogue history into the response selection and propose a\npersonalized hybrid matching network (PHMN). Our contributions are two-fold: 1)\nour model extracts personalized wording behaviors from user-specific dialogue\nhistory as extra matching information; 2) we perform hybrid representation\nlearning on context-response utterances and explicitly incorporate a customized\nattention mechanism to extract vital information from context-response\ninteractions so as to improve the accuracy of matching. We evaluate our model\non two large datasets with user identification, i.e., personalized Ubuntu\ndialogue Corpus (P-Ubuntu) and personalized Weibo dataset (P-Weibo).\nExperimental results confirm that our method significantly outperforms several\nstrong models by combining personalized attention, wording behaviors, and\nhybrid representation learning.\n"
    }
]